{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-JzTkvwW4GC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnxGl9RBW2fr"
      },
      "source": [
        "#### 1. Library installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5eRFVh_W3Cb",
        "outputId": "30b740df-e7a0-480b-9bed-8d64d04d9c97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Spacy and en_core_web_sm downloaded successfully.\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mtorchtext 0.6.0 installation initiated.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Install spacy\n",
        "subprocess.run([\"pip\", \"install\", \"spacy\", \"--quiet\"])\n",
        "\n",
        "# Download the English language model for spacy\n",
        "subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\", \"--quiet\"])\n",
        "\n",
        "print(\"Spacy and en_core_web_sm downloaded successfully.\")\n",
        "\n",
        "# Install torchtext==0.6.0 as it is an available version that can be used with the legacy API structure (but without the 'legacy' submodule).\n",
        "get_ipython().system('pip install torchtext==0.6.0 --quiet')\n",
        "\n",
        "print(\"torchtext 0.6.0 installation initiated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5OPQPMnWixO"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e15ku8NdWY-G"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "from torchtext import data, datasets\n",
        "import spacy\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET7gm6LEYQ-7"
      },
      "source": [
        "#### 3. Global configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bMP8TPkHWo9F"
      },
      "outputs": [],
      "source": [
        "# Set deterministic behavior\n",
        "RANDOM_SEED = 100\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Define Fields using SpaCy (en_core_web_sm)\n",
        "TEXT = data.Field(\n",
        "    tokenize='spacy',\n",
        "    tokenizer_language='en_core_web_sm',\n",
        "    batch_first=True,\n",
        "    include_lengths=True\n",
        ")\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "# Dataset partition sizes\n",
        "TRAIN_SIZE = 1000\n",
        "VALID_SIZE = 400\n",
        "TEST_SIZE  = 50\n",
        "\n",
        "# Vocabulary size\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Compute device specification\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# LSTM Network configs\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "N_EPOCHS = 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_90ysKoYtm1"
      },
      "source": [
        "#### 4. Load the full IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t2wCZNEYvmQ",
        "outputId": "e1794861-3780-45b4-aede-0dfcf45c2b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "First training example text: ['I', 'loved', 'this', 'movie', '!', 'It', \"'s\", 'truly', 'bizarre', ',', 'extremely', 'funny', ',', 'morbid', ',', 'witty', '...', 'It', 'makes', 'no', 'sense', 'to', 'tell', 'about', 'the', 'contents', 'of', 'the', 'movie', ',', 'because', 'then', 'I', \"'d\", 'be', 'giving', 'out', 'the', 'outcome', '!', 'You', 'have', 'to', 'see', 'it', 'without', 'knowing', 'what', 'is', 'it']...\n",
            "First training example label: pos\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")\n",
        "print(f\"First training example text: {train_data.examples[0].text[:50]}...\")\n",
        "print(f\"First training example label: {train_data.examples[0].label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZQLsE5oZVjf"
      },
      "source": [
        "#### 5. Create randomized sub-samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB06YZOCZNW4",
        "outputId": "7b461f55-392e-4cfa-bee2-a08815fc866f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset sub-sets after sampling:\n",
            "Number of training examples: 1000\n",
            "Number of validation examples: 400\n",
            "Number of testing examples: 50\n"
          ]
        }
      ],
      "source": [
        "def create_data_sub_samples():\n",
        "  \"\"\"\n",
        "  Creates dataset sub-samples for train, validation, and test sets.\n",
        "\n",
        "  Returns:\n",
        "  - train_subset: Subset of the training data.\n",
        "  - valid_subset: Subset of the validation data.\n",
        "  - test_subset: Subset of the test data.\n",
        "  \"\"\"\n",
        "\n",
        "  # Shuffle the original datasets\n",
        "  random.shuffle(train_data.examples)\n",
        "  random.shuffle(test_data.examples)\n",
        "\n",
        "  # Split the datasets\n",
        "  train_samples = train_data.examples[:TRAIN_SIZE]\n",
        "  valid_samples = train_data.examples[TRAIN_SIZE:TRAIN_SIZE + VALID_SIZE]\n",
        "  test_samples  = test_data.examples[:TEST_SIZE]\n",
        "\n",
        "  # Create new Dataset objects\n",
        "  train_subset = data.Dataset(train_samples, fields=train_data.fields)\n",
        "  valid_subset = data.Dataset(valid_samples, fields=train_data.fields)\n",
        "  test_subset  = data.Dataset(test_samples,  fields=test_data.fields)\n",
        "\n",
        "  return train_subset, valid_subset, test_subset\n",
        "\n",
        "train_subset, valid_subset, test_subset = create_data_sub_samples()\n",
        "print(\"Dataset sub-sets after sampling:\")\n",
        "print(f\"Number of training examples: {len(train_subset)}\")\n",
        "print(f\"Number of validation examples: {len(valid_subset)}\")\n",
        "print(f\"Number of testing examples: {len(test_subset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RKKz2Y1dI0e"
      },
      "source": [
        "#### 6. Build Vocabulary (train only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "i7gGyAITb1wJ"
      },
      "outputs": [],
      "source": [
        "TEXT.build_vocab(\n",
        "    train_subset,\n",
        "    max_size=MAX_VOCAB_SIZE,\n",
        "    vectors=\"glove.6B.100d\",\n",
        "    unk_init=torch.Tensor.normal_\n",
        ")\n",
        "\n",
        "LABEL.build_vocab(train_subset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "423fuhbWeixn"
      },
      "source": [
        "#### 7. Create iterators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YFLvifLWdlmt"
      },
      "outputs": [],
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_subset, valid_subset, test_subset),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krGe_cIHfKj0"
      },
      "source": [
        "#### 7. Sanity check a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpiguXB7fR2l",
        "outputId": "559eb27f-e379-4d6f-aac5-5fbaa3ce3b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text.shape: torch.Size([64, 87])\n",
            "text_lengths.shape: torch.Size([64])\n",
            "labels.shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "def check_batch(iterator):\n",
        "  batch = next(iter(iterator))\n",
        "\n",
        "  text, text_lengths = batch.text\n",
        "  labels = batch.label\n",
        "\n",
        "  print(f\"text.shape: {text.shape}\")                  # [batch_size, seq_len]\n",
        "  print(f\"text_lengths.shape: {text_lengths.shape}\")  # [batch_size]\n",
        "  print(f\"labels.shape: {labels.shape}\")              # [batch_size]\n",
        "\n",
        "check_batch(train_iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw5W3I6ClUL9"
      },
      "source": [
        "#### 8. Bi-Directional LSTM Model (with packed sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tW9mYVs-e54k"
      },
      "outputs": [],
      "source": [
        "class BiLSTMSentiment(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embedding_dim,\n",
        "        hidden_dim,\n",
        "        output_dim,\n",
        "        n_layers,\n",
        "        bidirectional,\n",
        "        dropout,\n",
        "        pad_idx\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=n_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if n_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        # text = [batch size, seq len]\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded = [batch size, seq len, emb dim]\n",
        "\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        # embedded = [seq len, batch size, emb dim]\n",
        "\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded,\n",
        "            text_lengths.cpu(),\n",
        "            enforce_sorted=False\n",
        "        )\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "\n",
        "        # hidden = [num layers * num directions, batch size, hidden dim]\n",
        "\n",
        "        hidden_forward = hidden[-2, :, :]\n",
        "        hidden_backward = hidden[-1, :, :]\n",
        "\n",
        "        hidden_cat = torch.cat((hidden_forward, hidden_backward), dim=1)\n",
        "\n",
        "        return self.fc(self.dropout(hidden_cat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LncStstZmANP"
      },
      "source": [
        "#### 9. Model Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EgqRqPaXlcJA"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = BiLSTMSentiment(\n",
        "    INPUT_DIM,\n",
        "    EMBEDDING_DIM,\n",
        "    HIDDEN_DIM,\n",
        "    OUTPUT_DIM,\n",
        "    N_LAYERS,\n",
        "    BIDIRECTIONAL,\n",
        "    DROPOUT,\n",
        "    PAD_IDX\n",
        ").to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wl_sjfcmmzF"
      },
      "source": [
        "#### 10. Load Pretrained GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "a9S9nTz7mgHs"
      },
      "outputs": [],
      "source": [
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6a9Ax3mxXV"
      },
      "source": [
        "#### 11. Optimizer & Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AlOiqK3zmtEy"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "criterion = criterion.to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFBUI-DHm-RR"
      },
      "source": [
        "#### 12. Training & Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "alPIxx8_m2Br"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded == y).float()\n",
        "    return correct.sum() / len(correct)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGK3RI02nOJr"
      },
      "source": [
        "#### 13. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6YJ6yZVbnJMt"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text, text_lengths = batch.text\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpYfgFO3nYiw"
      },
      "source": [
        "#### 14. Validation (evaluation) Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "E8UpEJFTnDaX"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Guk8rFnuQ0"
      },
      "source": [
        "#### 15. Model Training - training / validation loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3gXp77vnkW-",
        "outputId": "75aa0e28-7a10-4977-d4fa-b4eb643eb442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start of the training-validation loop..\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.695 | Train Acc: 0.508\n",
            "Val   Loss: 0.697 | Val   Acc: 0.491\n",
            "Epoch 2/10\n",
            "Train Loss: 0.689 | Train Acc: 0.543\n",
            "Val   Loss: 0.686 | Val   Acc: 0.549\n",
            "Epoch 3/10\n",
            "Train Loss: 0.677 | Train Acc: 0.587\n",
            "Val   Loss: 0.659 | Val   Acc: 0.623\n",
            "Epoch 4/10\n",
            "Train Loss: 0.651 | Train Acc: 0.619\n",
            "Val   Loss: 0.639 | Val   Acc: 0.665\n",
            "Epoch 5/10\n",
            "Train Loss: 0.603 | Train Acc: 0.695\n",
            "Val   Loss: 0.818 | Val   Acc: 0.565\n",
            "Epoch 6/10\n",
            "Train Loss: 0.576 | Train Acc: 0.706\n",
            "Val   Loss: 0.613 | Val   Acc: 0.661\n",
            "Epoch 7/10\n",
            "Train Loss: 0.520 | Train Acc: 0.753\n",
            "Val   Loss: 0.622 | Val   Acc: 0.647\n",
            "Epoch 8/10\n",
            "Train Loss: 0.494 | Train Acc: 0.773\n",
            "Val   Loss: 0.597 | Val   Acc: 0.667\n",
            "Epoch 9/10\n",
            "Train Loss: 0.450 | Train Acc: 0.800\n",
            "Val   Loss: 0.571 | Val   Acc: 0.710\n",
            "Epoch 10/10\n",
            "Train Loss: 0.431 | Train Acc: 0.807\n",
            "Val   Loss: 0.665 | Val   Acc: 0.661\n"
          ]
        }
      ],
      "source": [
        "def train_model(\n",
        "    model_,\n",
        "    train_iterator_,\n",
        "    valid_iterator_,\n",
        "    optimizer_,\n",
        "    criterion_,\n",
        "    n_epochs=N_EPOCHS):\n",
        "\n",
        "    print(f\"Start of the training-validation loop..\")\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        train_loss, train_acc = train(model_, train_iterator_, optimizer_, criterion_)\n",
        "        val_loss, val_acc = evaluate(model_, valid_iterator_, criterion_)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f}\")\n",
        "        print(f\"Val   Loss: {val_loss:.3f} | Val   Acc: {val_acc:.3f}\")\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "    model,\n",
        "    train_iterator,\n",
        "    valid_iterator,\n",
        "    optimizer,\n",
        "    criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzmkqHQSo3Q0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDnNMrjfpZKt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
